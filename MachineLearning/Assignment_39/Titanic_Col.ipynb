{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic_Col.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM+bZSR9Pf57DyfZ1yUE2s3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BJahanyar/Advanced_Python/blob/main/MachineLearning/Assignment_39/Titanic_Col.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtKQ_Pi0gsCs"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkJRQRAohZlW",
        "outputId": "09651248-8dec-4a96-e3ec-deb74e58adad"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "aFyv6HRlhauU",
        "outputId": "b784e754-d3fc-4647-f709-0a60da611001"
      },
      "source": [
        "train = pd.read_csv('drive/MyDrive/Colab Notebooks/Titanic Dataset/train.csv')\n",
        "train.head(2)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0            1         0       3  ...   7.2500   NaN         S\n",
              "1            2         1       1  ...  71.2833   C85         C\n",
              "\n",
              "[2 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "QylocZ4Fharu",
        "outputId": "007dfc85-daf4-4b4d-ef10-174a34217e63"
      },
      "source": [
        "#PreProcessing\n",
        "train= train.replace([\"female\" , \"male\"] , [0 , 1])\n",
        "train = train.replace([\"C\" , \"S\" , \"Q\"] , [0 , 1 , 2])\n",
        "train = train.fillna(0)\n",
        "train.head(2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare  Cabin  Embarked\n",
              "0            1         0       3  ...   7.2500      0       1.0\n",
              "1            2         1       1  ...  71.2833    C85       0.0\n",
              "\n",
              "[2 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROVaJ7E4haoB",
        "outputId": "1dcff029-7bc7-4a3e-b72a-2dcc08609e57"
      },
      "source": [
        "Y_train =  np.array(train[['Survived']])\n",
        "X_train = np.array(train[['Pclass', 'Sex', 'Fare', 'Age', 'SibSp', 'Parch', 'Embarked']])\n",
        "print(X_train.shape , Y_train.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(891, 7) (891, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNa8yqr9halV"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Dense(7,activation='sigmoid'),\n",
        "                                    tf.keras.layers.Dense(8,activation='relu'),\n",
        "                                    tf.keras.layers.Dense(6,activation='relu'),\n",
        "                                    tf.keras.layers.Dense(4,activation='relu'),\n",
        "                                    tf.keras.layers.Dense(2,activation='softmax')\n",
        "])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-nmw4r-hafr"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMDz0uvUhaZ9",
        "outputId": "92d66877-7b1b-4aec-b059-2779195ec0f3"
      },
      "source": [
        "output=model.fit(X_train,Y_train,epochs=500)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "28/28 [==============================] - 1s 1ms/step - loss: 0.7194 - accuracy: 0.4299\n",
            "Epoch 2/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.6038\n",
            "Epoch 3/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.6759 - accuracy: 0.6700\n",
            "Epoch 4/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.6698 - accuracy: 0.6723\n",
            "Epoch 5/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.6630 - accuracy: 0.6801\n",
            "Epoch 6/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.6527 - accuracy: 0.6891\n",
            "Epoch 7/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.6379 - accuracy: 0.6970\n",
            "Epoch 8/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.6220 - accuracy: 0.6914\n",
            "Epoch 9/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.6092 - accuracy: 0.6936\n",
            "Epoch 10/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5982 - accuracy: 0.6902\n",
            "Epoch 11/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5924 - accuracy: 0.6947\n",
            "Epoch 12/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5897 - accuracy: 0.7003\n",
            "Epoch 13/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5866 - accuracy: 0.6970\n",
            "Epoch 14/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5838 - accuracy: 0.6981\n",
            "Epoch 15/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5817 - accuracy: 0.7003\n",
            "Epoch 16/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.7015\n",
            "Epoch 17/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5779 - accuracy: 0.6992\n",
            "Epoch 18/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5742 - accuracy: 0.7015\n",
            "Epoch 19/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5710 - accuracy: 0.7026\n",
            "Epoch 20/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5668 - accuracy: 0.7048\n",
            "Epoch 21/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5632 - accuracy: 0.7015\n",
            "Epoch 22/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7149\n",
            "Epoch 23/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7116\n",
            "Epoch 24/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7250\n",
            "Epoch 25/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5459 - accuracy: 0.7306\n",
            "Epoch 26/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5419 - accuracy: 0.7262\n",
            "Epoch 27/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5399 - accuracy: 0.7262\n",
            "Epoch 28/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5321 - accuracy: 0.7374\n",
            "Epoch 29/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5297 - accuracy: 0.7340\n",
            "Epoch 30/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7318\n",
            "Epoch 31/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5229 - accuracy: 0.7407\n",
            "Epoch 32/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5135 - accuracy: 0.7576\n",
            "Epoch 33/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7430\n",
            "Epoch 34/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5077 - accuracy: 0.7654\n",
            "Epoch 35/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7497\n",
            "Epoch 36/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.5023 - accuracy: 0.7643\n",
            "Epoch 37/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4990 - accuracy: 0.7475\n",
            "Epoch 38/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7565\n",
            "Epoch 39/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.7609\n",
            "Epoch 40/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7609\n",
            "Epoch 41/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4906 - accuracy: 0.7688\n",
            "Epoch 42/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.7778\n",
            "Epoch 43/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4839 - accuracy: 0.7755\n",
            "Epoch 44/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4778 - accuracy: 0.7722\n",
            "Epoch 45/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4784 - accuracy: 0.7755\n",
            "Epoch 46/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4743 - accuracy: 0.7767\n",
            "Epoch 47/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4698 - accuracy: 0.7969\n",
            "Epoch 48/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.7856\n",
            "Epoch 49/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.7912\n",
            "Epoch 50/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7901\n",
            "Epoch 51/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7924\n",
            "Epoch 52/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7845\n",
            "Epoch 53/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.8025\n",
            "Epoch 54/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4545 - accuracy: 0.7957\n",
            "Epoch 55/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.7935\n",
            "Epoch 56/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4446 - accuracy: 0.7935\n",
            "Epoch 57/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.8013\n",
            "Epoch 58/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7980\n",
            "Epoch 59/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4416 - accuracy: 0.7969\n",
            "Epoch 60/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4451 - accuracy: 0.8070\n",
            "Epoch 61/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.8036\n",
            "Epoch 62/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4310 - accuracy: 0.8092\n",
            "Epoch 63/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.8081\n",
            "Epoch 64/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4330 - accuracy: 0.7991\n",
            "Epoch 65/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4361 - accuracy: 0.8081\n",
            "Epoch 66/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8081\n",
            "Epoch 67/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4368 - accuracy: 0.8092\n",
            "Epoch 68/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4264 - accuracy: 0.8126\n",
            "Epoch 69/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8036\n",
            "Epoch 70/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.8036\n",
            "Epoch 71/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8103\n",
            "Epoch 72/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.8081\n",
            "Epoch 73/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4211 - accuracy: 0.8126\n",
            "Epoch 74/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8103\n",
            "Epoch 75/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.8159\n",
            "Epoch 76/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4253 - accuracy: 0.8047\n",
            "Epoch 77/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4300 - accuracy: 0.8025\n",
            "Epoch 78/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4176 - accuracy: 0.8148\n",
            "Epoch 79/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4179 - accuracy: 0.8193\n",
            "Epoch 80/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8215\n",
            "Epoch 81/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4200 - accuracy: 0.8227\n",
            "Epoch 82/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4203 - accuracy: 0.8002\n",
            "Epoch 83/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4214 - accuracy: 0.8092\n",
            "Epoch 84/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.8182\n",
            "Epoch 85/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.8193\n",
            "Epoch 86/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4188 - accuracy: 0.8148\n",
            "Epoch 87/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4129 - accuracy: 0.8137\n",
            "Epoch 88/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4228 - accuracy: 0.8126\n",
            "Epoch 89/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8193\n",
            "Epoch 90/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4128 - accuracy: 0.8171\n",
            "Epoch 91/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4182 - accuracy: 0.8137\n",
            "Epoch 92/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4149 - accuracy: 0.8305\n",
            "Epoch 93/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8171\n",
            "Epoch 94/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4136 - accuracy: 0.8238\n",
            "Epoch 95/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4108 - accuracy: 0.8204\n",
            "Epoch 96/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.8272\n",
            "Epoch 97/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8260\n",
            "Epoch 98/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4134 - accuracy: 0.8227\n",
            "Epoch 99/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8238\n",
            "Epoch 100/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.8238\n",
            "Epoch 101/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4087 - accuracy: 0.8260\n",
            "Epoch 102/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4122 - accuracy: 0.8249\n",
            "Epoch 103/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4089 - accuracy: 0.8260\n",
            "Epoch 104/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4054 - accuracy: 0.8272\n",
            "Epoch 105/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8227\n",
            "Epoch 106/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4030 - accuracy: 0.8294\n",
            "Epoch 107/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8182\n",
            "Epoch 108/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4117 - accuracy: 0.8204\n",
            "Epoch 109/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4134 - accuracy: 0.8238\n",
            "Epoch 110/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4042 - accuracy: 0.8249\n",
            "Epoch 111/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8193\n",
            "Epoch 112/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8260\n",
            "Epoch 113/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 0.8283\n",
            "Epoch 114/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4080 - accuracy: 0.8193\n",
            "Epoch 115/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4040 - accuracy: 0.8260\n",
            "Epoch 116/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4149 - accuracy: 0.8260\n",
            "Epoch 117/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8193\n",
            "Epoch 118/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4022 - accuracy: 0.8328\n",
            "Epoch 119/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3981 - accuracy: 0.8305\n",
            "Epoch 120/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.4087 - accuracy: 0.8249\n",
            "Epoch 121/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4064 - accuracy: 0.8249\n",
            "Epoch 122/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4023 - accuracy: 0.8294\n",
            "Epoch 123/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4041 - accuracy: 0.8260\n",
            "Epoch 124/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3999 - accuracy: 0.8294\n",
            "Epoch 125/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4021 - accuracy: 0.8249\n",
            "Epoch 126/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3998 - accuracy: 0.8272\n",
            "Epoch 127/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3996 - accuracy: 0.8294\n",
            "Epoch 128/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4059 - accuracy: 0.8238\n",
            "Epoch 129/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8305\n",
            "Epoch 130/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4011 - accuracy: 0.8249\n",
            "Epoch 131/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4034 - accuracy: 0.8249\n",
            "Epoch 132/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3987 - accuracy: 0.8283\n",
            "Epoch 133/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8272\n",
            "Epoch 134/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4001 - accuracy: 0.8328\n",
            "Epoch 135/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8260\n",
            "Epoch 136/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4077 - accuracy: 0.8249\n",
            "Epoch 137/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3972 - accuracy: 0.8305\n",
            "Epoch 138/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3954 - accuracy: 0.8260\n",
            "Epoch 139/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3992 - accuracy: 0.8215\n",
            "Epoch 140/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8227\n",
            "Epoch 141/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.8272\n",
            "Epoch 142/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4043 - accuracy: 0.8339\n",
            "Epoch 143/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.8305\n",
            "Epoch 144/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3959 - accuracy: 0.8305\n",
            "Epoch 145/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8260\n",
            "Epoch 146/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4013 - accuracy: 0.8305\n",
            "Epoch 147/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4033 - accuracy: 0.8238\n",
            "Epoch 148/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4010 - accuracy: 0.8316\n",
            "Epoch 149/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3965 - accuracy: 0.8283\n",
            "Epoch 150/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3962 - accuracy: 0.8260\n",
            "Epoch 151/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3984 - accuracy: 0.8316\n",
            "Epoch 152/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8294\n",
            "Epoch 153/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4001 - accuracy: 0.8373\n",
            "Epoch 154/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.8328\n",
            "Epoch 155/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3991 - accuracy: 0.8328\n",
            "Epoch 156/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3933 - accuracy: 0.8373\n",
            "Epoch 157/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4018 - accuracy: 0.8283\n",
            "Epoch 158/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3976 - accuracy: 0.8283\n",
            "Epoch 159/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8350\n",
            "Epoch 160/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3982 - accuracy: 0.8406\n",
            "Epoch 161/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3994 - accuracy: 0.8305\n",
            "Epoch 162/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.8260\n",
            "Epoch 163/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8283\n",
            "Epoch 164/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3927 - accuracy: 0.8350\n",
            "Epoch 165/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4010 - accuracy: 0.8272\n",
            "Epoch 166/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.4042 - accuracy: 0.8272\n",
            "Epoch 167/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3957 - accuracy: 0.8328\n",
            "Epoch 168/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3989 - accuracy: 0.8238\n",
            "Epoch 169/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3910 - accuracy: 0.8339\n",
            "Epoch 170/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3905 - accuracy: 0.8373\n",
            "Epoch 171/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3925 - accuracy: 0.8339\n",
            "Epoch 172/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3955 - accuracy: 0.8361\n",
            "Epoch 173/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3937 - accuracy: 0.8316\n",
            "Epoch 174/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.8283\n",
            "Epoch 175/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3947 - accuracy: 0.8429\n",
            "Epoch 176/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3985 - accuracy: 0.8305\n",
            "Epoch 177/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.8350\n",
            "Epoch 178/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3925 - accuracy: 0.8373\n",
            "Epoch 179/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8339\n",
            "Epoch 180/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3856 - accuracy: 0.8384\n",
            "Epoch 181/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3943 - accuracy: 0.8283\n",
            "Epoch 182/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3942 - accuracy: 0.8440\n",
            "Epoch 183/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3946 - accuracy: 0.8294\n",
            "Epoch 184/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3989 - accuracy: 0.8339\n",
            "Epoch 185/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3925 - accuracy: 0.8272\n",
            "Epoch 186/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3889 - accuracy: 0.8384\n",
            "Epoch 187/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8328\n",
            "Epoch 188/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3875 - accuracy: 0.8373\n",
            "Epoch 189/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.8373\n",
            "Epoch 190/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8350\n",
            "Epoch 191/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3893 - accuracy: 0.8305\n",
            "Epoch 192/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3858 - accuracy: 0.8406\n",
            "Epoch 193/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3907 - accuracy: 0.8395\n",
            "Epoch 194/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3961 - accuracy: 0.8350\n",
            "Epoch 195/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3959 - accuracy: 0.8350\n",
            "Epoch 196/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3929 - accuracy: 0.8350\n",
            "Epoch 197/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8384\n",
            "Epoch 198/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3875 - accuracy: 0.8406\n",
            "Epoch 199/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8384\n",
            "Epoch 200/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3965 - accuracy: 0.8272\n",
            "Epoch 201/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3846 - accuracy: 0.8440\n",
            "Epoch 202/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8373\n",
            "Epoch 203/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3878 - accuracy: 0.8418\n",
            "Epoch 204/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3885 - accuracy: 0.8395\n",
            "Epoch 205/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8361\n",
            "Epoch 206/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8361\n",
            "Epoch 207/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3946 - accuracy: 0.8395\n",
            "Epoch 208/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3903 - accuracy: 0.8395\n",
            "Epoch 209/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3904 - accuracy: 0.8384\n",
            "Epoch 210/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3950 - accuracy: 0.8361\n",
            "Epoch 211/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3864 - accuracy: 0.8350\n",
            "Epoch 212/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.8418\n",
            "Epoch 213/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3836 - accuracy: 0.8429\n",
            "Epoch 214/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8339\n",
            "Epoch 215/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3857 - accuracy: 0.8361\n",
            "Epoch 216/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8395\n",
            "Epoch 217/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8418\n",
            "Epoch 218/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8361\n",
            "Epoch 219/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3852 - accuracy: 0.8384\n",
            "Epoch 220/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3931 - accuracy: 0.8316\n",
            "Epoch 221/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3863 - accuracy: 0.8406\n",
            "Epoch 222/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8429\n",
            "Epoch 223/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3837 - accuracy: 0.8429\n",
            "Epoch 224/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3837 - accuracy: 0.8384\n",
            "Epoch 225/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8294\n",
            "Epoch 226/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3849 - accuracy: 0.8451\n",
            "Epoch 227/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3845 - accuracy: 0.8350\n",
            "Epoch 228/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.8429\n",
            "Epoch 229/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3891 - accuracy: 0.8395\n",
            "Epoch 230/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8395\n",
            "Epoch 231/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8384\n",
            "Epoch 232/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8406\n",
            "Epoch 233/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3876 - accuracy: 0.8406\n",
            "Epoch 234/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3862 - accuracy: 0.8384\n",
            "Epoch 235/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8361\n",
            "Epoch 236/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3900 - accuracy: 0.8373\n",
            "Epoch 237/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3850 - accuracy: 0.8373\n",
            "Epoch 238/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.8384\n",
            "Epoch 239/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3842 - accuracy: 0.8429\n",
            "Epoch 240/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3961 - accuracy: 0.8316\n",
            "Epoch 241/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8474\n",
            "Epoch 242/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.8395\n",
            "Epoch 243/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8384\n",
            "Epoch 244/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8440\n",
            "Epoch 245/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3862 - accuracy: 0.8373\n",
            "Epoch 246/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8451\n",
            "Epoch 247/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3865 - accuracy: 0.8373\n",
            "Epoch 248/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8451\n",
            "Epoch 249/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8361\n",
            "Epoch 250/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8429\n",
            "Epoch 251/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3854 - accuracy: 0.8395\n",
            "Epoch 252/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.8451\n",
            "Epoch 253/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3843 - accuracy: 0.8440\n",
            "Epoch 254/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8418\n",
            "Epoch 255/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8418\n",
            "Epoch 256/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8406\n",
            "Epoch 257/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8395\n",
            "Epoch 258/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4028 - accuracy: 0.8294\n",
            "Epoch 259/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8316\n",
            "Epoch 260/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3914 - accuracy: 0.8328\n",
            "Epoch 261/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3833 - accuracy: 0.8339\n",
            "Epoch 262/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3876 - accuracy: 0.8373\n",
            "Epoch 263/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8350\n",
            "Epoch 264/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.8328\n",
            "Epoch 265/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3952 - accuracy: 0.8350\n",
            "Epoch 266/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3834 - accuracy: 0.8418\n",
            "Epoch 267/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3899 - accuracy: 0.8316\n",
            "Epoch 268/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8429\n",
            "Epoch 269/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3833 - accuracy: 0.8440\n",
            "Epoch 270/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8350\n",
            "Epoch 271/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3830 - accuracy: 0.8384\n",
            "Epoch 272/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3946 - accuracy: 0.8272\n",
            "Epoch 273/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8440\n",
            "Epoch 274/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3820 - accuracy: 0.8373\n",
            "Epoch 275/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8395\n",
            "Epoch 276/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8462\n",
            "Epoch 277/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3834 - accuracy: 0.8406\n",
            "Epoch 278/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3966 - accuracy: 0.8350\n",
            "Epoch 279/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8462\n",
            "Epoch 280/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8373\n",
            "Epoch 281/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8530\n",
            "Epoch 282/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3906 - accuracy: 0.8361\n",
            "Epoch 283/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3841 - accuracy: 0.8339\n",
            "Epoch 284/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3854 - accuracy: 0.8339\n",
            "Epoch 285/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3844 - accuracy: 0.8451\n",
            "Epoch 286/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3849 - accuracy: 0.8429\n",
            "Epoch 287/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8328\n",
            "Epoch 288/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8462\n",
            "Epoch 289/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8451\n",
            "Epoch 290/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3827 - accuracy: 0.8451\n",
            "Epoch 291/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8462\n",
            "Epoch 292/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8418\n",
            "Epoch 293/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8418\n",
            "Epoch 294/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3818 - accuracy: 0.8418\n",
            "Epoch 295/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8384\n",
            "Epoch 296/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3848 - accuracy: 0.8418\n",
            "Epoch 297/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8496\n",
            "Epoch 298/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.8406\n",
            "Epoch 299/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8395\n",
            "Epoch 300/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3819 - accuracy: 0.8451\n",
            "Epoch 301/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8429\n",
            "Epoch 302/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8451\n",
            "Epoch 303/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3859 - accuracy: 0.8339\n",
            "Epoch 304/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8462\n",
            "Epoch 305/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8429\n",
            "Epoch 306/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8530\n",
            "Epoch 307/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3894 - accuracy: 0.8316\n",
            "Epoch 308/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3798 - accuracy: 0.8451\n",
            "Epoch 309/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3787 - accuracy: 0.8418\n",
            "Epoch 310/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3788 - accuracy: 0.8440\n",
            "Epoch 311/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3820 - accuracy: 0.8406\n",
            "Epoch 312/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8451\n",
            "Epoch 313/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8418\n",
            "Epoch 314/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8519\n",
            "Epoch 315/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8507\n",
            "Epoch 316/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3839 - accuracy: 0.8474\n",
            "Epoch 317/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8451\n",
            "Epoch 318/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8395\n",
            "Epoch 319/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8406\n",
            "Epoch 320/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3846 - accuracy: 0.8462\n",
            "Epoch 321/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8440\n",
            "Epoch 322/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.8384\n",
            "Epoch 323/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8474\n",
            "Epoch 324/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3795 - accuracy: 0.8429\n",
            "Epoch 325/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8418\n",
            "Epoch 326/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.8406\n",
            "Epoch 327/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8474\n",
            "Epoch 328/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3796 - accuracy: 0.8462\n",
            "Epoch 329/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3781 - accuracy: 0.8496\n",
            "Epoch 330/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8496\n",
            "Epoch 331/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3828 - accuracy: 0.8350\n",
            "Epoch 332/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8350\n",
            "Epoch 333/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3836 - accuracy: 0.8395\n",
            "Epoch 334/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3846 - accuracy: 0.8429\n",
            "Epoch 335/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8474\n",
            "Epoch 336/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3831 - accuracy: 0.8462\n",
            "Epoch 337/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8462\n",
            "Epoch 338/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8496\n",
            "Epoch 339/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8474\n",
            "Epoch 340/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8429\n",
            "Epoch 341/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3749 - accuracy: 0.8418\n",
            "Epoch 342/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8418\n",
            "Epoch 343/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8384\n",
            "Epoch 344/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8451\n",
            "Epoch 345/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.8395\n",
            "Epoch 346/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3791 - accuracy: 0.8406\n",
            "Epoch 347/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8418\n",
            "Epoch 348/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8451\n",
            "Epoch 349/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8440\n",
            "Epoch 350/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8350\n",
            "Epoch 351/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8395\n",
            "Epoch 352/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3854 - accuracy: 0.8462\n",
            "Epoch 353/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8440\n",
            "Epoch 354/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8406\n",
            "Epoch 355/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8373\n",
            "Epoch 356/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3777 - accuracy: 0.8440\n",
            "Epoch 357/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8474\n",
            "Epoch 358/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3753 - accuracy: 0.8451\n",
            "Epoch 359/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3787 - accuracy: 0.8485\n",
            "Epoch 360/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8395\n",
            "Epoch 361/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3843 - accuracy: 0.8373\n",
            "Epoch 362/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8328\n",
            "Epoch 363/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8440\n",
            "Epoch 364/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8429\n",
            "Epoch 365/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.8384\n",
            "Epoch 366/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8451\n",
            "Epoch 367/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8451\n",
            "Epoch 368/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3762 - accuracy: 0.8451\n",
            "Epoch 369/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8451\n",
            "Epoch 370/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 0.8384\n",
            "Epoch 371/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3898 - accuracy: 0.8316\n",
            "Epoch 372/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8350\n",
            "Epoch 373/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8384\n",
            "Epoch 374/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8451\n",
            "Epoch 375/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3756 - accuracy: 0.8519\n",
            "Epoch 376/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8373\n",
            "Epoch 377/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8485\n",
            "Epoch 378/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8440\n",
            "Epoch 379/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8440\n",
            "Epoch 380/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8451\n",
            "Epoch 381/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3762 - accuracy: 0.8496\n",
            "Epoch 382/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8474\n",
            "Epoch 383/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8474\n",
            "Epoch 384/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3808 - accuracy: 0.8418\n",
            "Epoch 385/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8485\n",
            "Epoch 386/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3734 - accuracy: 0.8519\n",
            "Epoch 387/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8496\n",
            "Epoch 388/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8462\n",
            "Epoch 389/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8395\n",
            "Epoch 390/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8462\n",
            "Epoch 391/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8406\n",
            "Epoch 392/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3800 - accuracy: 0.8384\n",
            "Epoch 393/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3765 - accuracy: 0.8440\n",
            "Epoch 394/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8507\n",
            "Epoch 395/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8552\n",
            "Epoch 396/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3787 - accuracy: 0.8474\n",
            "Epoch 397/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8316\n",
            "Epoch 398/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3827 - accuracy: 0.8395\n",
            "Epoch 399/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8339\n",
            "Epoch 400/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3975 - accuracy: 0.8361\n",
            "Epoch 401/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3784 - accuracy: 0.8474\n",
            "Epoch 402/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3788 - accuracy: 0.8418\n",
            "Epoch 403/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8496\n",
            "Epoch 404/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8373\n",
            "Epoch 405/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8485\n",
            "Epoch 406/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8451\n",
            "Epoch 407/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8474\n",
            "Epoch 408/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8451\n",
            "Epoch 409/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3795 - accuracy: 0.8429\n",
            "Epoch 410/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8451\n",
            "Epoch 411/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8474\n",
            "Epoch 412/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3764 - accuracy: 0.8496\n",
            "Epoch 413/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3852 - accuracy: 0.8485\n",
            "Epoch 414/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3793 - accuracy: 0.8462\n",
            "Epoch 415/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8451\n",
            "Epoch 416/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3807 - accuracy: 0.8440\n",
            "Epoch 417/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8530\n",
            "Epoch 418/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3747 - accuracy: 0.8462\n",
            "Epoch 419/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8474\n",
            "Epoch 420/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8406\n",
            "Epoch 421/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8406\n",
            "Epoch 422/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.8462\n",
            "Epoch 423/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3869 - accuracy: 0.8462\n",
            "Epoch 424/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8451\n",
            "Epoch 425/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8395\n",
            "Epoch 426/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8462\n",
            "Epoch 427/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8451\n",
            "Epoch 428/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3780 - accuracy: 0.8519\n",
            "Epoch 429/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8440\n",
            "Epoch 430/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8462\n",
            "Epoch 431/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8462\n",
            "Epoch 432/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8406\n",
            "Epoch 433/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3773 - accuracy: 0.8384\n",
            "Epoch 434/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3787 - accuracy: 0.8440\n",
            "Epoch 435/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8507\n",
            "Epoch 436/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3765 - accuracy: 0.8462\n",
            "Epoch 437/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8496\n",
            "Epoch 438/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8429\n",
            "Epoch 439/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3735 - accuracy: 0.8418\n",
            "Epoch 440/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8406\n",
            "Epoch 441/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8406\n",
            "Epoch 442/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.8462\n",
            "Epoch 443/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3824 - accuracy: 0.8316\n",
            "Epoch 444/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8496\n",
            "Epoch 445/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8418\n",
            "Epoch 446/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.8451\n",
            "Epoch 447/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3796 - accuracy: 0.8440\n",
            "Epoch 448/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8451\n",
            "Epoch 449/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8429\n",
            "Epoch 450/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8384\n",
            "Epoch 451/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8429\n",
            "Epoch 452/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3833 - accuracy: 0.8361\n",
            "Epoch 453/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8418\n",
            "Epoch 454/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8507\n",
            "Epoch 455/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8507\n",
            "Epoch 456/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3736 - accuracy: 0.8440\n",
            "Epoch 457/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3768 - accuracy: 0.8541\n",
            "Epoch 458/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3777 - accuracy: 0.8496\n",
            "Epoch 459/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3796 - accuracy: 0.8384\n",
            "Epoch 460/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3726 - accuracy: 0.8519\n",
            "Epoch 461/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3731 - accuracy: 0.8530\n",
            "Epoch 462/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3783 - accuracy: 0.8485\n",
            "Epoch 463/500\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3806 - accuracy: 0.8395\n",
            "Epoch 464/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8418\n",
            "Epoch 465/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8462\n",
            "Epoch 466/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8429\n",
            "Epoch 467/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8451\n",
            "Epoch 468/500\n",
            "28/28 [==============================] - 0s 1ms/step - loss: 0.3779 - accuracy: 0.8395\n",
            "Epoch 469/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8462\n",
            "Epoch 470/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8575\n",
            "Epoch 471/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8485\n",
            "Epoch 472/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8429\n",
            "Epoch 473/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8395\n",
            "Epoch 474/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8474\n",
            "Epoch 475/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3796 - accuracy: 0.8440\n",
            "Epoch 476/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3732 - accuracy: 0.8440\n",
            "Epoch 477/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8496\n",
            "Epoch 478/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.8462\n",
            "Epoch 479/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8440\n",
            "Epoch 480/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3720 - accuracy: 0.8530\n",
            "Epoch 481/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3710 - accuracy: 0.8507\n",
            "Epoch 482/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8552\n",
            "Epoch 483/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8462\n",
            "Epoch 484/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8530\n",
            "Epoch 485/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3782 - accuracy: 0.8485\n",
            "Epoch 486/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8519\n",
            "Epoch 487/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3734 - accuracy: 0.8496\n",
            "Epoch 488/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8519\n",
            "Epoch 489/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8384\n",
            "Epoch 490/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8418\n",
            "Epoch 491/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.8373\n",
            "Epoch 492/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8451\n",
            "Epoch 493/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8462\n",
            "Epoch 494/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8507\n",
            "Epoch 495/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8440\n",
            "Epoch 496/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3767 - accuracy: 0.8440\n",
            "Epoch 497/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.8373\n",
            "Epoch 498/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8440\n",
            "Epoch 499/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8316\n",
            "Epoch 500/500\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "76Z67b2OhaUp",
        "outputId": "d2f7a4d0-f132-4a86-baa5-c6105232e499"
      },
      "source": [
        "plt.plot(output.history['loss'], c = 'red')\n",
        "plt.plot(output.history['accuracy'], c ='green')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "tp7CivHhhaRa",
        "outputId": "b73f6a20-3b88-48b9-84d8-52beca333f48"
      },
      "source": [
        "test = pd.read_csv('drive/MyDrive/Colab Notebooks/Titanic Dataset/test.csv')\n",
        "test = test.replace(['female','male'],[0, 1])\n",
        "test = test.replace(['S','C','Q'],[0, 1, 2])\n",
        "test=test.fillna(0)\n",
        "test.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>3</td>\n",
              "      <td>Kelly, Mr. James</td>\n",
              "      <td>1</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330911</td>\n",
              "      <td>7.8292</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>3</td>\n",
              "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
              "      <td>0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>363272</td>\n",
              "      <td>7.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>2</td>\n",
              "      <td>Myles, Mr. Thomas Francis</td>\n",
              "      <td>1</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>240276</td>\n",
              "      <td>9.6875</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>3</td>\n",
              "      <td>Wirz, Mr. Albert</td>\n",
              "      <td>1</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>315154</td>\n",
              "      <td>8.6625</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>3</td>\n",
              "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
              "      <td>0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3101298</td>\n",
              "      <td>12.2875</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Pclass  ... Cabin  Embarked\n",
              "0          892       3  ...     0         2\n",
              "1          893       3  ...     0         0\n",
              "2          894       2  ...     0         2\n",
              "3          895       3  ...     0         0\n",
              "4          896       3  ...     0         0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "4V8Am-SdhaHb",
        "outputId": "1c8715e3-2405-41e8-c2a0-426564fb417c"
      },
      "source": [
        "survived = pd.read_csv('drive/MyDrive/Colab Notebooks/Titanic Dataset/gender_submission.csv')\n",
        "survived.head(2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived\n",
              "0          892         0\n",
              "1          893         1"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jpn1pJHihqbE",
        "outputId": "0e462ded-42d8-41ed-92e8-4f79b9dcbfe6"
      },
      "source": [
        "X_test = np.array(test[['Pclass','Sex','Age','SibSp','Parch','Fare','Embarked']])\n",
        "Y_test = np.array(survived[['Survived']])\n",
        "print(X_train.shape , Y_train.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(891, 7) (891, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVnjVyEKhqYF"
      },
      "source": [
        "from keras import layers\n",
        "layer = layers.Normalization()\n",
        "layer.adapt(X_test)\n",
        "X_test = layer(X_test).numpy()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWKlSCGchqUR",
        "outputId": "8ac067f2-946d-4c77-cc9b-8287aa8d3b67"
      },
      "source": [
        "acc=model.evaluate(X_test,Y_test)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 0s 1ms/step - loss: 0.2040 - accuracy: 0.9139\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5depZCMhw04",
        "outputId": "27dac0d3-1d6b-46ae-9893-e0bc4151f9af"
      },
      "source": [
        "Kelly=np.array([3,1,27,0,0,8.6,0])\n",
        "Kelly=Kelly.reshape(1,7)\n",
        "y_pred=model.predict(Kelly)\n",
        "prediction=np.argmax(y_pred)\n",
        "print('prediction  ----> ',prediction)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction  ---->  0\n"
          ]
        }
      ]
    }
  ]
}